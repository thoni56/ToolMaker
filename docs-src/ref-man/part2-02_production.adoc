// PAGE 76 -- ParserMaker Reference Manual

// STATUS: XRefs

= PARSER PRODUCTION

== Creating a Running Parser

// @XREF: The Options Section

The figure below gives an overview over the relation between the files required and produced by ParserMaker.
The prefix `_pm_` is chosen by the parser implementor and is dependent on the system prefix and the parser prefix (see _The Options Section_ on page 86), and the file names for any produced target source code module is target language dependent.

// @FIG 2: Convert to SVG.

[[fig2]]
.Files used and produced by ParserMaker.
image::Fig-2-1_temp.gif[width=40%,align="center"]

// @TODO: Consider formatting the 'pm' prefix in bold instead of italic
//        (`__pm__File.x` => `**pm**File.x`) because the italic text
//        segment is too slanted in the final document, and bold might
//        be easier to read.

Depending on the target language used the produced target language modules, may be one or more files, e.g. for C there will be one `__pm__Parse.c` and one `__pm__Parse.h` created for the module `__pm__Parse`.

// PAGE 77

Following the above figure, this following is a step by step instruction how to use ParserMaker in order to create a working system.

// @XREF: THE TOOLMAKER DESCRIPTION FILE
// @XREF: ToolMaker System Description
// @XREF: The ParserMaker Description File
// @XREF: THE PARSERMAKER COMMAND

1. Create a ToolMaker description file (`__pm__.tmk`) according to the specifications in _THE TOOLMAKER DESCRIPTION FILE_ in the _ToolMaker System Description_, page 30.
This step is not necessary if you are developing a stand-alone parser (in this case the information can be put inside `__pm__.pmk` instead).

2. Create a ParserMaker description (grammar) file (`__pm__.pmk`) according to the specifications in _The ParserMaker Description File_ on page 79.

3. Invoke ParserMaker on the grammar file (see _THE PARSERMAKER COMMAND_ on page 104).
Repeat this step until there are no input errors.

4. Compile the ParserMaker generated components (e.g. `__pm__Parse.c` and `__pm__PaSema.c`).

5. Create and compile other system components including a main program that calls the parser.
If you use the ToolMaker kit, a lot of these modules will already have been created for you.

6. Link the object modules and execute.


// @XREF: Toolmake Reference Manual

Points 1 and 2 can be simplified by invoking _**toolmake**_ to set up a development environment for you (see the _Toolmake Reference Manual_).

// @ADMONITION: Note was converted to TIP!
// @NOTE: Highlighter marker formatting (below) added by porter!

TIP: In rare cases the description files are not sufficient to capture all the target dependencies or special requirements for a project, and you have to modify the parser skeletons.
If this is the case copy the files `Parse.imp` and `Err.imp` to the development directory from the appropriate library and modify them.
#TO DO THIS IT IS ABSOLUTELY NECESSARY THAT YOU HAVE A THOROUGH UNDERSTANDING OF THE SYSTEM.#
Change the library option in the ParserMaker description file to point to the directory where the modified skeletons resides.
When ParserMaker is executed, it will use these skeletons instead of the standard ones.


=== File Descriptions

==== Input Files

// @XREF: The ParserMaker Description File

_ParserMaker Description file_ (`.pmk`), also known as the _Grammar file_.
This file contains a definition of the input grammar according to the specifications in _The ParserMaker Description File_ on page 79.

// PAGE 78

_ToolMaker Common Description file_ (`.tmk`) contains definitions common for all Makers.
ParserMaker uses common options and the token definition from this file.


==== Output Files

_Table and definition file_ (`.pmt`).
This intermediate file is only kept when the option `Generate Tables` is set.
It contains all the definitions and parser tables necessary to create a final parser and is normally removed after successful generation of source files.

_Vocabulary file_ (`.voc`).
Contains the representation of the terminal symbols and constitutes the interface between the scanner and the parser.
It is used by ScannerMaker to construct a scanner for the language.

// @XREF: The List Directive

_List file_ (`.pml`).
The contents of the list file is controlled by the List-directive (see _The List Directive_ on page 91).
A complete list file contains the following:

* Pretty printed grammar (`List Grammar;`).
* Generated item set (`List Items;`).
* Generated parser tables (`List Tables;`).
* Packed parser tables (`List Tables;`).
* Statistical information (`List Statistics;`).
* Informational messages (`List Info;`).
* Source code listing (`List Input;`).

_Parser module_ (`__pm__Parse`).
Target language dependent parser module.
Created from the `Parse.imp` file where definitions, interfaces and tables have been incorporated.
Depending on the target language one or more files may be produced, e.g. for C the files `__pm__Parse.c` and `__pm__Parse.h` are produced.
The directives `Pack` and `Recovery` defines much of the layout of the file.

_Semantic module_ (`__pm__PaSema`).
Target dependent semantic module.
The file is created from the skeleton file `Parse.imp` and contains semantic actions and other target dependent code supplied by the parser implementor.

_Error recovery interface module_ (`__pm__Err`).
Target dependent.
The file is created from the skeleton file `Err.imp` and contains error recovery routines that constitute an interface to the ListerMaker list system.

All output files from ParserMaker are created in the current directory.

// PAGE 79

== The ParserMaker Description File

// @NOTE: Maybe we could reduce the number of XRefs here, since Asciidoctor
//        provides enough info to implicitly indicate Part and App. title!
// @XREF: appendix C
// @XREF: ToolMaker System Description
// @XREF: SYNTAX NOTATION

This section describes the format of the ParserMaker description file.
The notation used to do this is a modified EBNF.
For a brief description of this refer to appendix C in the _ToolMaker System Description_, _SYNTAX NOTATION_, page 52.


=== Lexical Definitions

This chapter defines the lexical symbols of the ParserMaker description language.


==== Character Set

// @CHECK: "IS constructed" => "ARE"?

Symbols in the ParserMaker language is constructed by using upper case characters (all upper case characters including multi-national ISO-8859 characters), lower case characters (ISO-8859) and digits.

// SYNTAX: EBNF

------------------------------
<letter> ::=
    <upper case letter> | <lower case letter>
------------------------------

// @XREF: (see below) => add xref link?

All symbols defined by the parser implementor in the ParserMaker description file are case sensitive, e.g. `Begin` is different from `BEGIN`.
Reserved words and keywords (see below) are not case sensitive.

// @XREF: Common Directives

In the target dependent parts of the ParserMaker language, any character is accepted (see _Common Directives_ on page 87 for a description of how to specify the escape character).


==== Lexical Items and Spacing Conventions

The ParserMaker language consists of a sequence of lexical items (tokens).
Tokens are identifiers, reserved words, keywords, numbers, strings, delimiters and comments.

The tokens may be separated by any number of spaces, horizontal tabulates or new lines.
Tokens are indivisible, space must not occur within tokens, except for strings and comments.

Identifiers are used as names (nonterminals, terminals, attributes), and keywords.

// SYNTAX: EBNF

------------------------------
<identifier> ::= <letter> {<letter> | <digit> '_'}
------------------------------

All characters in an identifier are significant.
Lower case letters are different from upper case letters in all identifiers except keywords.
Example:

// SYNTAX: EBNF

------------------------------
TERMINAL    terminal definition
------------------------------

// PAGE 80

===== Reserved words

A reserved word is an identifier preceded by the character pair `%%`.
No space is allowed within the token.
The reserved words are predefined and can be used in special contexts only.
Letter case is not significant for reserved words.
The reserved words are:

// @TODO: Convert list to table? (would take less space)

* `%%TERMINALS`
* `%%ATTRIBUTES`
* `%%RECOVERY`
* `%%RULES`
* `%%DECLARATIONS`
* `%%OPTIONS`
* `%%END`
* `%%EXPORT`
* `%%SCANNER`
* `%%INSERTSYMBOL`
* `%%IMPORT`
* `%%SRCP`
* `%%TOKEN`


===== Keywords

A keyword is an identifier with a predefined meaning.
A keyword can however be used as any other identifier in the language.
Letter case is not significant for keywords.
The keywords are:

// @NOTE: The keywords are not alpha-/ASCII-betically sorted
//        (they are here as in the original). Should we sort them?

// @TODO: Convert list to table? (would take less space)

* `ACTIONPACK`
* `ATTRIBUTES`
* `CODE`
* `COLUMN`
* `ERROR`
* `ERRORHANDLER`
* `ESCAPE`
* `FIDUCIAL`
* `FILE`
* `FORCE`
* `GCS`
* `GENERATE`
* `GOTOPACK`
* `GRAMMAR`
* `HEIGHT`
* `HELP`
* `INFO`
* `INPUT`
* `ITEMS`
* `LES`
* `LIBRARY`
* `LIST`
* `LISTERPREFIX`
* `LR0`
* `LOOKAHEADMAX`
* `META`
* `MULTIPLE`
* `NAME`
* `NO`
* `OPTIMIZE`
* `OS`
* `PACK`
* `PANIC`
* `POSITION`
* `PREFIX`
* `RDS`
* `RECOVERY`
* `RESOLVE`
* `ROW`
* `RR`
* `SEPARATOR`
* `SHIFTCOST`
* `SINGLE`
* `SKIP`
* `SR`
* `SRCP`
* `SOURCE`
* `STACKLIMIT`
* `STACKSIZE`
* `STATISTICS`
* `TABLES`
* `TARGET`
* `TRACE`
* `VERBOSE`
* `WIDTH`

// PAGE 81

===== Numbers

A number is an integer literal.
It can be written in either decimal or hexadecimal form.

// SYNTAX: EBNF

------------------------------
<number> ::= <decimal integer> | <hexadecimal integer>

<decimal integer> ::= <digit> {<digit>}

<hexadecimal integer> ::= '#' <hex digit> {<hex digit>}

<hex digit> ::= <digit>
             | 'A' | 'B' | 'C' | 'D' | 'E' | 'F'
             | 'a' | 'b' | 'c' | 'd' | 'e' | 'f'
------------------------------

Example:

........................
255     #FF     0     #0
........................


===== Strings

A string in ParserMaker is a sequence of characters, at least one, enclosed in bracket characters.
Two string types are used -- the quoted string and the angle bracketed string.

// SYNTAX: EBNF

------------------------------
<string> ::= <quoted string> | <angle bracketed string>

<quoted string> ::=
    ''' <character> {<character>} '''

<angle bracketed string> ::=
    '<' <character> {<character>} '>'
------------------------------

// PAGE 82

If a quoted string is to contain the character `'` it must be preceded by the character `\`.
The right angle is not allowed in angle bracketed strings.

Example:

......
'*'     '=>'     'BEGIN'     'end'
'\'A quoted string\''

<identifier>     <any character, but %%>
......


===== Terminals, Nonterminals and Attributes

In the _terminals_, _attributes_, _recovery_ and _rules sections_ the symbols `TERMINAL`, `NONTERMINAL` and `ATTRIBUTE` are considered terminal symbols.
They are defined as follows


// SYNTAX: EBNF

------------------------------
TERMINAL ::= <identifier>
          |  <angle bracketed string>
          |  <quoted string>

NONTERMINAL ::= <identifier>
             |  <angle bracketed string>

ATTRIBUTE ::= <identifier>
------------------------------


===== Delimiters and Special Tokens

ParserMaker defines the following single character delimiters:

// @TODO: Convert list to table? (would take less space)

* `=`
* `;`
* `,`
* `(`
* `)`
* `!`
* `{`
* `}`
* `|`
* `[`
* `]`

and the special tokens:

// @TODO: Convert list to table? (would take less space)

* `%%`
* `%+`
* `%-`
* `=>`


===== Comments

A comment starts with two dashes, `--`, and is terminated by an end of line.
A comment has no effect on the meaning of the ParserMaker language.

// PAGE 83

Example:

......
     -- A single comment

-- A long comment
-- must be split into several lines
......


===== Escape character

// @CHECK: ESCAPE CHARACTER -- It's not clear from the original text whether
//         the escape char is a backtick ( ` ) or an apostrophe ( ' ), because
//         the word processor used for typesetting the book seems to
//         have "smart-formatted" the typographic symbols to curly quotes!
//         I think it's a backtick, but I'll need to check again by looking
//         at the examples in "Common Directives" section.

// @XREF: Common Directives

In the semantic actions, the character `{backtick}` is used as an escape character.
A character following the escape character will always be copied to the output.
The escape character may be changed by means of the escape option (see _Common Directives_ on page 87).

Example: to include the character `%` in a semantic action it must be written `{backtick}%`

NOTE. The escape character is valid only in the target dependent code parts of the input description.


=== Overall Structure of the Description File

// SYNTAX: EBNF

------------------------------
<description file> ::=
    <toolmaker sections>
    <other sections>
    <rules section>

<toolmaker sections> ::=
    [ <options section> ]
    { <import section> | <srcp section> | <token section> }

<other sections> ::=
    { <declarations section>
    | <terminals section>
    | <attributes section>
    | <recovery section>
    | <export section>
    | <scanner section>
    | <insertsymbol section>
    | <deletesymbol section> }
------------------------------

The ParserMaker description file may contain thirteen different sections: the _options section_, the _import section_, the _srcp section_, the _token section_, the _declarations section_, the _terminal section_, the _attribute section_, the _recovery section_, the _export section_, the _scanner section_, the _insertsymbol section_, the _deletesvmbol section_ and the _rules section_.


All sections except the _rules section_ are optional.
The rules section must be the last section, the option section must be first if it exists and the import, token and srcp sections must, if they exist, immediately follow the option section.
Otherwise the order between the sections is free.

// PAGE 84

The _options section_ controls the ParserMaker generation process.
For instance, the degree of table packing, included error recovery facilities and the kind of logging information produced.

// @XREF: THE TOOLMAKER DESCRIPTION FILE
// @XREF: ToolMaker System Description

The _import_, _token_ and _srcp sections_ are further described in _THE TOOLMAKER DESCRIPTION FILE_ in the _ToolMaker System Description_, page 30.
These three sections are normally located in the ToolMaker description file and should be put in the ParserMaker description file only when developing a stand-alone parser.

// @CHECK GRAMMAR: "DEFINES target" => "DEFINE"? (sing.)

The _declarations_, _export_, _insertsymbol_, _deletesymbol_ and _scanner sections_ defines target dependent code that should be included in the produced parser.

// @CHECK GRAMMAR: "SPECIFIES the input" => "SPECIFY"? (sing.)

The _terminals_, _attributes_ and _recovery sections_ together with the _rules section_ specifies the input language.
It contain facilities for tuning the automatically generated error recovery system, defining the scanner interface, handling ambiguous grammars and defining semantic actions.


=== An Example

To give a short overview of what the description file may look like, a small example will be presented.

The problem: Assume that a file contains a sequence of telegrams.

Each telegram consists of one or more sentences terminated by the symbol `STOP`.
A telegram ends with the symbol `ZZZZ`.
The problem is to analyse a telegram file and for each telegram write a summary containing the total number of words in the telegram (excluding `STOP` and `ZZZZ`) and all words exceeding 12 characters.

Preconditions: The target language is C.
A scanner exists which recognizes the tokens:

// SYNTAX: ToolMaker description file?

------------------------------
WORD
'STOP'
'ZZZZ'
END-OF-FILE
------------------------------

// @XREF: The Scanner Section

When a `WORD` is recognized the scanner returns the length of the `WORD`.
The lexical attribute `LENGTH` is used to hold this value.
The scanner call interface is defined in the scanner section (see _The Scanner Section_ on page 96).
The token section is shown here for completeness but is normally defined in the ToolMaker description file.

Example: A file containing the text:

// PAGE 85

.......................................
I WILL ARRIVE AT 5 PM STOP THE HOTEL IS
INTERNATIONALE STOP
ZZZZ
.......................................

will result in the output:

.........................
Words = 10
Words > 12 = 1
.........................

The solution:

// @CHECK: Carefully compare to original scans!
// @EXTERNALIZE SOURCE: C example: Telegram
// SYNTAX: C + IMP macros? (generated)

------------------------------
%%TOKEN
    CODE code;
    ATTRIBUTES
        LENGTH;

%%SCANNER tgrScan(tgrCtxt, token);

%%DECLARATIONS

#include <stdio.h>
int wordCount;
int moreThan12Chars;

%%TERMINALS
    WORD = 2;
    'STOP' = 3;
    'ZZZZ' = 4;

%%RULES

telegrams
    = telegram
    ! telegrams telegram
    ;

telegram
    =
      %%
        wordCount = 0;
        moreThan12Chars = 0;
      %%
    sentences 'ZZZZ'
      %%
        printf("Words = &%u\n", wordCount);
        printf("Words > 12 = &%u\n", moreThan12Chars);
      %%
    ;

sentences
    = sentence
    ! sentences sentence
    ;

sentence
    = word list 'STOP'
    ;

word_list
    = element
    ! word_list element
    ;

element
    = WORD
        %%
            wordCount++;
            /* Look at the length */
            if (%WORD.length > 12) {
                moreThan12Chars++;
            }/*if*/
        %%
    ;
------------------------------

// PAGE 86

=== The Options Section

// SYNTAX: EBNF

------------------------------
<options section> ::=
    '%%OPTIONS' <directive> {<directive>} ['%%END']

<directive> ::=
      <common directive>
    | <listerprefix directive>
    | <errorhandler directive>
    | <trace directive>
    | <lookaheadmax directive>
    | <shiftcost directive>
    | <stacklimit directive>
    | <pack directive>
    | <line directive>
    | <list directive>
    | <optimize directive>
    | <recovery directive>
    | <resolve directive>
    | <vocabulary directive>
    | <table file directive>
    | <list file directive>
------------------------------

// @XREF: Options
// @XREF: The Options Section
// @XREF: ToolMaker System Description

The _options section_ of the ParserMaker description file controls the parser generation process.
Corresponding options can be given as command line parameters to ParserMaker at its invocation.
Options given as command line parameters override those within the description file.
Command line options are described in _Options_ on page 104.
For a detailed discussion on options see _The Options Section_ in the _ToolMaker System Description_, page 30.

The directives can be given in any order.
If a directive is repeated, only the last one given is used.

Note that if a directive is explicitly stated in the _options section_, all its default options are turned off.
This means that all desired options must be included when a directive is used explicitly, not just the desired extra ones, which is especially important for set valued directives.
The default setting of the options are


// SYNTAX: ToolMaker description file

------------------------------
Listerprefix 'tm';
Errorhandler;
No Trace;
Lookaheadmax 5;
Shiftcost 5;
Stacklimit 32;
Pack RDS;
No Line;
List Info;
Optimize LrO;
Recovery Single, Multiple, Panic;
Resolve SR;
------------------------------


// PAGE 87

==== Common Directives

// SYNTAX: EBNF

------------------------------
<common directive> ::=
      <target directive>
    | <os directive>
    | <prefix directive>
    | <library directive>
    | <escape directive>
    | <width directive>
    | <height directive>
    | <generate directive>
    | <force directive>
------------------------------

// @XREF: The Options Section
// @XREF: ToolMaker System Description

The common directives are directives available for all of the Makers in the ToolMaker kit.
For a detailed description of these refer to _The Options Section_ in the _ToolMaker System Description_, page 30.
All directives are available for ParserMaker, and if used overrides default values and settings in the ToolMaker Common Description file.

The prefix directive does not inherit its default value, instead it defaults to `_pm_` if not explicitly set in the `.tmk` file.
If set in the ToolMaker Common Description file and not used in the ParserMaker Description file it defaults to the system prefix (the value set in the ToolMaker Common Description file).


==== The ListerPrefix Directive

// SYNTAX: EBNF

------------------------------
<listerprefix directive> ::=
    'LISTERPREFIX' <quoted string> ';'
------------------------------

// @XREF: ListerMaker Reference Manual

// @CHECK GRAMMAR: "that DOES not use" = "DO" (sing.) if it refers to the
//                 Lister modules, but the whole sentence is rather entangled
//                 and unclear. Should be polished.

To be able to interface the generated error message handler to ToolMaker generated Lister modules (see _ListerMaker Reference Manual_) that does not use the default prefix this directive can be used.
The quoted string will be used as a prefix in all function calls to the Lister.

The default is the system prefix, i.e. ParserMaker assumes that the Lister is generated using the system prefix, which unless set otherwise in the ToolMaker description file is `tm`.


==== The Errorhandler Directive

// SYNTAX: EBNF

------------------------------
<errorhandler directive> ::=
    ['NO'] 'ERRORHANDLER' ';'
------------------------------

// PAGE 88

// @XREF: Run-Time Interface

This option turns on [off] generation of the parser error handling interface routines.
See _Run-Time Interface_ on page 107 for a definition of these routines.

The default is:

// SYNTAX: ToolMaker description file

------------------------------
ErrorHandler;
------------------------------


==== The Trace Directive

// SYNTAX: EBNF

------------------------------
<trace directive> ::=
    ['NO'] 'TRACE' ';'
------------------------------

The trace directive instructs ParserMaker to include _trace printing_ functions in the generated parser.
This information can, together with the information in the list file give information which simplifies the debugging of the grammar.

The default value of the trace directive is:

// SYNTAX: ToolMaker description file

------------------------------
No Trace;
------------------------------


==== The LookAheadMax Directive

// SYNTAX: EBNF

------------------------------
<lookaheadmax directive> ::=
    'LOOKAHEADMAX' <number> ';'
------------------------------

// @XREF: Error Recovery Principles

This option defines _the maximum amount of look-ahead that will be applied when the parser detects a syntax error_.
The default value of 5 represents a reasonable functionality versus performance trade-off.
See _Error Recovery Principles_ on page 72 for a discussion of the impact of this option.
Any positive integer value larger than or equal to 4 may be used as value.
Due to performance reasons, it is not recommended to increase the look-ahead above 6.


==== The ShiftCost Directive

// SYNTAX: EBNF

------------------------------
<shiftcost directive> ::=
    'SHIFTCOST' <number> ';'
------------------------------

// @XREF: Error Recovery Principles

This option defines the acceptance cost for shifting one symbol from the input.
See _Error Recovery Principles_ on page 72 for a discussion of the impact of this option.
Any positive integer may be used as the value.
The default is:

// SYNTAX: ToolMaker description file

------------------------------
ShiftCost 5;
------------------------------


==== The StackLimit Directive

// SYNTAX: EBNF

------------------------------
<stacklimit directive> ::=
    'STACKLIMIT' <number> ';'
------------------------------

// PAGE 89

This option defines _the size of the parse stack_, and the default value of 32 should be enough for all but the most demanding situations.
If a parse stack overflow occurs in the generated parser (indicated by error message 106 in the default error handler), this constant can be increased.
Note however that the most common reason for parse stack overflow is that the grammar is _right recursive_, i.e. it contains one or more rules of the form:

// SYNTAX: ToolMaker description file

------------------------------
<a> = b <a>
    ! b
    ;
------------------------------

where `b` may be one or more symbols.
This is not an error per se, but writing rules this way prevents any reductions to be performed until an entire construct, e.g. an entire list, has been recognized.
If the text to be analysed contains long lists, the parse stack may grow out of bounds.
The most general way to deal with this kind of problem is to transform the grammar to be _left recursive_, i.e. to eliminate all right recursive rules.
The rule above can be transformed to:

// SYNTAX: ToolMaker description file

------------------------------
<a> = <a> b
    ! b
    ;
------------------------------

This form of rule permits a reduction to be performed for every element of the construct, e.g. for every element of a list, and parse stack size will normally not be a problem.
Note however that care must be taken when the rules are transformed so that an equivalent grammar is constructed.

If parser size is an issue, this constant should be decreased since each stack entry will occupy memory needed to accommodate all of the defined attributes, both the terminal attributes and the non-terminal attributes.
The stack size may be set to any positive integer value.

The default value is:

// SYNTAX: ToolMaker description file

------------------------------
StackLimit 32;
------------------------------


==== The Pack Directives

// SYNTAX: EBNF

------------------------------
<pack directive> ::=
      'PACK' <pack option>
            {',' <pack option>} ';'
    | ['NO'] 'PACK' ';'
    | 'ACTIONPACK' <pack option>
            {',' <pack option>} ';'
    | 'GOTOPACK' <pack option>
            {',' <pack option>} ';'

<pack option> ::=
    'ROW' | 'COLUMN' | 'RDS' |
    'GCS' | 'LES' | 'ERROR'
------------------------------

// PAGE 90

The pack directives guide the parse table packing.
The directive `PACK` will pack both action and goto tables, `ACTIONPACK` will only affect the packing of the action table and finally `GOTOPACK` will only affect the packing of the goto table.
High degree of table packing normally increases the execution time.

The implication of the `ROW` and `COLUMN` options is that identical rows and columns of the tables will be merged.

The `RDS` option stands for _Row Displacement Scheme_.
With this method the table will be linearized to a vector.
The rows of the original table will overlap each other in the constructed vector, and an attempt is made to store only significant elements.
If used in conjunction with `GCS` or `LES`, the error matrix method will be used for error detection, otherwise a check vector will be constructed in order to detect error entries.

The `GCS` option stands for _Graph Colouring Scheme_.
This means that compatible rows and columns will be represented by a single row or column.
When this packing technique is used, a binary error matrix will be constructed for error detection.

The `LES` option stands for _Line Elimination Scheme_.
This means that columns and rows with a single action will be moved out from the table.
A binary error matrix is constructed for error detection.

The implication of the `ERROR` option is that identical rows and columns of the error matrix will be merged.
If the contents of the unpacked error matrix is not unfavourable, and the space requirements for the table is not substantial, the effect of this packing method may in fact result in increased space requirements!

If `NO PACK` is specified, there will be no packing of the tables.

If you specify `PACK` without any options or if this directive is not specified, the default setting is:

// SYNTAX: ToolMaker description file

------------------------------
Pack RDS;
------------------------------

// @MISSING TEXT: "Refer to ??? for more information" there must have been
//                a reference there that was lost during editing of the
//                original manual. Try and guess what could have been there!

which gives a reasonable trade-off between table space and execution time.
Refer to [.red]#[MISSING TEXT]# for more information on how to select which table packing to use.


==== The Line Directive

// SYNTAX: EBNF

------------------------------
<list directive> ::= ['NO'] 'LINE' ';'
------------------------------

// @GRAMMAR: The following paragraph is really entangled and hard to read!

The line directive instructs ParserMaker to generate line number information in the generated source so that compilers and debuggers will believe that the source is the actual description file instead of the generated source file.
This can not be handy in initial stages of compiling the semantic actions and debugging, but as advanced debugger allows you to point in the source to find variables it is not always good.
Also this option might not have any effect for every of the supported languages (cf. the C-language preprocessor directive `#line`).


// PAGE 91

==== The List Directive

// SYNTAX: EBNF

------------------------------
<list directive> ::=
      'LIST' <list option>
        {',' <list option>} ';'
    | ['NO'] 'LIST' ';'

<list option> ::=
      'INPUT' | 'GRAMMAR' | 'ITEMS'
    | 'TABLES' | 'STATISTICS' | 'INFO'
------------------------------

The list directive controls the output listings from the parser generation.

With the `INPUT` option activated, a listing of the input description file with the input grammar and error messages concerning the input will be placed in the _list file_ (`.pml`).

The `GRAMMAR` option activates the output of a _formatted version of the input grammar_ to the list file.

// @GRAMMAR: "Even if the options are RESET" => "UNSET"?

Options `ITEMS` and `TABLES` output the _generated item set_ and the _produced tables_.
For large grammars the output listings becomes huge if these options are set.
Even if the options are reset, error messages and appropriate parts of the item set will be produced in case of errors in the generation process.

The `STATISTICS` option indicates that some _statistical information_ will be printed on the list file.

The `INFO` option indicates that _informational messages_ (or more precisely, messages with information severity) will be printed to the list file and the terminal.
The implication of having the `INFO` option turned off is that only error messages with warning severity or greater will be printed.
This can be useful if a huge amount of uninteresting informational messages is produced, thus preventing interesting error messages to be shown.

If the List directive is specified as `LIST` (without any options) or not specified at all, the default options are:

// SYNTAX: ToolMaker description file

------------------------------
List Info;
------------------------------


==== The Optimize Directive

// SYNTAX: EBNF

------------------------------
<optimize directive> ::=
      'OPTIMIZE' [<optimize option>
                 {',' <optimize option>}] ';'
    | ['NO'] 'OPTIMIZE' ';'

<optimize option> ::= 'LR0'
------------------------------

// PAGE 92

The optimize directive guides the level of optimization applied when the parse tables are computed.
Currently there is only one option, `LR0`, which will remove a certain kind of parser states -- _LR(0) reduce states_.
This can significantly reduce the size of the parser tables.

If `NO OPTIMIZE` is specified there will be no optimization.

If `OPTIMIZE` is specified without options or if the directive is left out, the default setting is:

// @CHECK: Is "Lr0;" (lowercase) in original! => "LR0;" (uppercase) ???

// SYNTAX: ToolMaker description file

------------------------------
Optimize Lr0;
------------------------------



==== The Recovery Directive

// SYNTAX: EBNF

------------------------------
<recovery directive ::=
      'RECOVERY' [<error option>
                 {','  <error option>}] ';'
    | ['NO'] 'RECOVERY' ';'

<error option> ::=
    'SINGLE' | 'MULTIPLE' | 'PANIC'
------------------------------

The recovery directive defines the degree of error recovery to apply.

Option `SINGLE` implies that a first level of _single symbol error correction_ should be applied.

Activating the `MULTIPLE` option means that the _second level_ should be invoked when the first fails.
If `SINGLE` is not activated, the second level is activated first.
The second level correction continues until the string is corrected or until it tries to delete an important symbol (fiducial) and the `PANIC` option is specified.

// @XREF: Error Recovery Principles

`PANIC` indicates that the last step in the recovery is pure _panic mode_.
Refer to the section _Error Recovery Principles_ on page 72 for further details.

`NO RECOVERY` means that the parser will _abort the parsing process_ if an error is detected.

If the recovery directive is specified as `RECOVERY` (without any options) or not specified at all, the default options are:

// SYNTAX: ToolMaker description file

------------------------------
Recovery Single, Multiple, Panic;
------------------------------


==== The Resolve Directive

// SYNTAX: EBNF

------------------------------
<resolve directive> ::=
      'RESOLVE' <resolve option>
                {',' <resolve option>} ';'
    | ['NO'] 'RESOLVE' ';'

<resolve option> ::=
    'SR' | 'RR'
------------------------------

// PAGE 93

The resolve directive defines how to react to ambiguities in the input grammar.

Option `SR` implies that a shift-reduce conflict shall be resolved by using shift in favour of reduce.

Option `RR` implies that a reduce-reduce conflict shall be resolved by reducing the production that comes first in the input grammar.

// @XREF: Grammar Ambiguity and LALR-conflicts

If `NO RESOLVE` is specified _no tables are created_ if conflicts are not removed by modifications, i.e. the generation is aborted on any conflict.
Also refer to _Grammar Ambiguity and LALR-conflicts_ on page 68.

The default setting, which you get if the directive is not specified or if it is specified without options, is:

// SYNTAX: ToolMaker description file

------------------------------
Resolve SR;
------------------------------


=== The Import, Export and Declarations Sections

// SYNTAX: EBNF

------------------------------
<import section> ::=
    '%%IMPORT' <target language code> ['%%END']

<export section> ::=
    '%%EXPORT' <target language code> ['%%END']

<declarations section> ::=
    '%%DECLARATIONS' <target language code> ['%%END']
------------------------------

The semantic actions in the _rules section_ are written in the target language extended with an attribute propagation technique.
Variables and subroutines referenced within the semantic routines are defined in the _import_ and _declaration sections_.
Using the _export section_ variables and functions declared in the declaration section may be exported.
These particular sections should contain _declarations and routines in the target language_.
The character sequences, representing the code, are copied unformatted to the output file.

NOTE: If the character sequence `%%` appears in the code, at least one of the percent signs (preferably both) must be quoted with the escape character.

Example: A C interface might be written:

// @EXTERNALIZE SOURCE: C + IMP macros
// SYNTAX: C + IMP macros? (generated)

------------------------------
%%EXPORT

extern void push(element);
extern int pop();

%%DECLARATION

#define LENGTH 10
static int stack[LENGTH];
static int ptr = 0;

void push(element)
int element;
{
    if (ptr < LENGTH) stack[ptr++] = element;
}/*push()*/

int pop()
{
    if (ptr > 0) return stack[--ptr];
}/*pop()*/
------------------------------

// PAGE 94

Target dependent errors in the _import_, _export_ and _declaration__ sections_ will not be detected until the generated code is run through the target compiler.


=== The Terminals Section

// SYNTAX: EBNF

------------------------------
<terminals section> ::=
    '%%TERMINALS' {<terminal definition> ';'} ['%%END']

<terminal definition> ::=
    TERMINAL '=' <token code> [<error recovery data>]

<token code> ::= <number>

<error recovery data> ::=
    ',' <insert cost> ',' <delete cost>[<print symbol>]

<insert cost> ::= <number>

<delete cost> ::= <number>

<print symbol> ::= '=>' TERMINAL
------------------------------

The _terminals section_ defines the scanner interface and is optional.
If omitted, ParserMaker will supply pertinent defaults.
If present, it should define the terminal symbols used in the grammar and the token codes returned by the scanner.
Information for error recovery improvement can be supplied with each terminal.

The left hand side of the definition is a terminal symbol.
The terminal is written exactly as it is used in the subsequent grammar.
The `<token code>` is a positive integer value that the scanner must return in order for the generated parser to recognize the token.
If the _terminals section_ is omitted ParserMaker will generate an internal number for each token.


Example:

// SYNTAX: ToolMaker description file

------------------------------
%%TERMINALS
    <identifier> = 2;
    NUMBER = 3;
    ';' 4;
------------------------------

// PAGE 95

IMPORTANT: Code values 0 and 1 must not be used.
Token code 0 is reserved by the system and code 1 is used for the endmarker.
The endmarker must not be included in the terminal list.

The optional error recovery information makes it possible for a parser implementor to tune the error recovery handler.
The insert cost and delete cost values define the cost of inserting and deleting the terminal symbol respectively.
The higher the cost, the more seldom the symbol will be inserted or deleted in the error recovery process.
Both the insert cost and the delete cost default to one (1).

The print symbol defines the string to be used in error messages and in the error repair process instead of the terminal symbol itself.
This facility applies normally only to pseudo terminals, i.e. terminals like identifiers and numbers, which are identified both with a type and a value.
The default print symbol is the terminal string itself.

Example: An identifier might be defined as:

// SYNTAX: ToolMaker description file

------------------------------
%%TERMINALS
    <identifier> = 10, 5, 1 => 'GENID00';
------------------------------

An identifier has the token code `10`, and it is expensive to insert an identifier compared to deleting it (`5` versus `1`), and if an identifier is inserted, `GENID00` will be issued in its place in the error message.

Example: The definition:

// SYNTAX: ToolMaker description file

------------------------------
<identifier> = 10;
------------------------------

is equivalent to:

------------------------------
<identifier> = 10, 1, 1 => '<identifier>';
------------------------------

// @XREF: Error Recovery Principles
// @XREF: The Insertsymbol Section
// @XREF: The Deletesymbol Section
// @XREF: Error Recovery

How these weights and the print name are used is described in _Error Recovery Principles_ on page 72, in _The Insertsymbol Section_ on page 97, _The Deletesymbol Section_ on page 97 and in _Error Recovery_ on page 106.


=== The Attributes Section

// SYNTAX: EBNF

------------------------------
<attributes section> ::=
    '%%ATTRIBUTES'
    <grammar attribute> {',' <grammar attribute>} ';'
    ['%%END']

<grammar attribute> ::=
    <identifier> [ '%%' <target language code> '%%' ]
------------------------------

// PAGE 96

The _attributes section_ defines the semantic attributes used in the grammar.
Language dependent declarations, i.e. a description of the implementation, are defined in the optional declaration part of each attribute.

Example:

// SYNTAX: ToolMaker description file

------------------------------
%%ATTRIBUTES
    ival %% int ival %%,
    pos  %% long pos %%;
------------------------------

Instead of repeating the name of the identifier in the target language declaration, it is possible to use a `%1` as a placeholder for the name.
It will automatically be substituted with the name in the produced code.

Example:

// SYNTAX: ToolMaker description file

------------------------------
%%ATTRIBUTES
    ival %% int %1 %%,
    pos  %% long %1 %%;
------------------------------

// @XREF: Grammar Attributes

How to use attributes is described in _Grammar Attributes_ on page 64.


=== The Scanner Section

// SYNTAX: EBNF

------------------------------
<scanner section> ::=
    '%%SCANNER' <target language code> ['%%END']
------------------------------

// @XREF: The Token Section
// @XREF: ToolMaker System Description

The code specified in the scanner section is executed when a new token should be read from the input stream.
The target language code is copied into the generated parser.
The purpose of this code is to fill the token structure as supplied by the pre-defined pointer variable token which is defined when the scanner section is entered.
See _The Token Section_ in the _ToolMaker System Description_, page 36 for a description of the fields in the token structure and how to define them.

The _scanner section_ can be viewed as a procedure with the following formal interface:

// SYNTAX: ???

[subs=quotes]
............................................................
_scanner section_(lexContext , token)

lexContext: INOUT %%(ScannerContext)
token: OUT %%(tokenType)
............................................................

Example:

// SYNTAX: ToolMaker description file

------------------------------
%%IMPORT
#include "smScan.h"

%%SCANNER
    smScan(lexContext, token);
%%END
------------------------------

// PAGE 97

If this section is omitted, default code will be generated:

// SYNTAX: ToolMaker description file

------------------------------
%%(tmkPrefix)Scan(lexContext, token);
------------------------------

// @XREF: The Prefix Directive
// @XREF: ToolMaker System Description

where `%%(tmkPrefix)` stands for (and will be expanded to) the system prefix, i.e. the code generated will assume that the scanner is a scanner generated by ScannerMaker using the common prefix (see _The Prefix Directive_ in the _ToolMaker System Description_, page 32 for a description of how to define a system prefix).



=== The Insertsymbol Section

// SYNTAX: EBNF

------------------------------
<insertsymbol section> ::=
    '%%INSERTSYMBOL' <target language code> ['%%END']
------------------------------

// @XREF: Run-Time Interface

This block should contain the necessary _target language code to construct a semantically valid token_ when the parser error recovery process has decided to insert a token in the input stream.
The code is inserted into the `__pm__ISym()` function.
See _Run-Time Interface_ on page 107 for further details.


=== The Deletesymbol Section

// SYNTAX: EBNF

------------------------------
<deletesymbol section> ::=
    '%%DELETESYMBOL' <target language code> ['%%END']
------------------------------

// @XREF: Run-Time Interface

This block should contain the necessary _target language code to handle the deletion of an already constructed token_ when the parser error recovery process has decided to delete a token from the input stream.
The code is inserted into the `__pm__DSym()` function.
See _Run-Time Interface_ on page 107 for further details.


=== The Recovery Section

// SYNTAX: EBNF

------------------------------
<recovery section> ::=
    '%%RECOVERY'
    [<meta part>]
    [<separator part>]
    [<fiducial part>]
    [<skip part>]
    ['%%END']
------------------------------

The _recovery section_ is optional.
It defines language dependent information that will improve the error recovery system.


==== The Meta Part

// SYNTAX: EBNF

------------------------------
<meta part> ::=
    'META' {<meta name> '=' '(' TERMINAL
        {',' TERMINAL} ')' ['=>' TERMINAL] ';'}
------------------------------

The meta part defines alias names for groups of symbols.
For example, OPERATOR can be defined to be the alias name for all operators.
The alias name will then be used both in error messages and in the first level repair process.
This facility will improve the quality of error messages and the speed of the recovery process.

// PAGE 98

The `meta name` is the name of the alias.
The terminal list defines the symbols that are covered by the alias name.
The terminals within the list must have equal insertion costs.
Any specific terminal must not appear in more than one meta definition.
The meta name will be used only when all the terminals in the list are accepted in the error state.
Only the single symbol error correction is affected.
The optional `'=>' TERMINAL` means that the indicated terminal will be used in the repair process.
If not specified, an arbitrary symbol is used.

Example:

// SYNTAX: ToolMaker description file??

------------------------------
META 'UNARY' = ('-', '+', 'NOT') => '-';
------------------------------

means that `UNARY` will be used in error messages for errors concerning `-`, `+` and `NOT`.
If a unary operator is missing, the symbol `-` will be used in the correction.


==== The Separator Part

// SYNTAX: EBNF

------------------------------
<separator part> ::=
    'SEPARATOR' '(' TERMINAL {',' TERMINAL} ')' ';'
------------------------------

The separator part is used to improve the second level recovery.
It contains symbols which separates recursive lists in the grammar.
Specifying a set of separators will result in greatly improved second level recovery, since the number of grammar productions that are taken into account during error recovery will become significantly larger.

Example: for a Pascal grammar, the following declaration would be appropriate:

// SYNTAX: ToolMaker description file
------------------------------
SEPARATOR(',', ';', ':');
------------------------------


==== The Fiducial Part

// SYNTAX: EBNF

------------------------------
<fiducial part> ::=
    'FIDUCIAL' '(' TERMINAL {',' TERMINAL} ')' ';'
------------------------------

The fiducial part defines the important symbols for the second level and panic mode recovery techniques.
_Fiducial symbols_ are symbols that start significant structures of the specified language.

For Pascal, `CONST`, `VAR`, `TYPE`, `LABEL`, `PROCEDURE` and the header symbols of statements, such as `BEGIN`, `WHILE`, `FOR`, could be selected.

// PAGE 99

==== The Skip Part

// SYNTAX: EBNF

------------------------------
<skip part> ::=
    'SKIP' '(' TERMINAL {',' TERMINAL} ')' ';'
------------------------------

The skip part is intended to improve the second level recovery.
The symbols specified in the skip part have the opposite meaning to the symbols in the fiducial part.
Skip symbols are tokens that appear in many contexts and should not be regarded as safe restarting symbols.

The specified symbols will always be deleted in the second level error recovery process.
In Pascal, identifiers and constants are good skip symbol candidates.


=== The Rules Section

// SYNTAX: EBNF

------------------------------
<rules section> ::=
    '%%RULES' {NONTERMINAL  <alternatives> ','}
    ['%%END']

<alternatives> ::=
    <right hand side> {'!' <right hand side>}

<right hand side> ::=  <components> <opt modify>

<components> ::= {<component>}

<component> ::=
      <symbol>
    | <action modify>
    | '(' <components> {'|'<components>} ')'
    | '{' <components> '}'
    | '[' <components> ']'

<symbol> ::= TERMINAL | NONTERMINAL

<action modify> ::=
    <opt modify> <semantic action> <opt modify>

<semantic action> ::=
    '%%' <any character sequence, but %%> '%%'

<opt modify> ::=
    {('%+' | '%-') '(' TERMINAL {',' TERMINAL} ')'}
------------------------------

The _rules section_ defines the syntax of the input language.
The input specification is written in an EBNF-like notation, extended with semantic actions and a mechanism for resolving ambiguities in the grammar.

// @XREF: CONCEPTS AND ASSUMPTIONS

The concepts behind the various constructs in the rules section are discussed at length in _CONCEPTS AND ASSUMPTIONS_ on page 60.


// PAGE 100

== The ToolMaker Common Description File

// @XREF: THE TOOLMAKER DESCRIPTION FILE
// @XREF: ToolMaker System Description

Unless ParserMaker is the only Maker used, common declarations of the source position and the token structures should be placed in the ToolMaker Common Description file which is described in _THE TOOLMAKER DESCRIPTION FILE_ in the _ToolMaker System Description_, page 30.
Otherwise these two sections may be specified in the ParserMaker Description file, removing any need for the ToolMaker Common Description file.


== The List File

The list file is used for various purposes:

* list the input and point out syntactic and other errors.
* log information about the parser generation process.
* log information about errors encountered in the process.

// @NOTE: "This CHAPTER" => "This SECTION"?

This chapter contains information on how to interpret the contents of the list file.


=== Format of the Pretty Printed Grammar

The pretty printed grammar is written to the list file if option `List Grammar;` is activated.
It is divided in two parts, the _vocabulary_ and the _productions_.

The _vocabulary_ contains:

* The _terminals_ with their internal code, token code, insertion cost, deletion cost and print symbol.
* The _non-terminals_ with their internal code.

The _productions_ list contains all productions pretty printed together with their _production number_.

The internal codes of the vocabulary and the production numbers are later used when the item set and the tables are printed.


=== Format of the Generated Item Set

// @XREF: The Trace Directive
// @BIBLIO_ENTRY: [Aho]

The LALR(1) item set is written to the list file if the option `List Items;` is activated.
A subset of the item set is also written if the grammar contains errors.
This may provide useful information in conjunction with the trace output printed if the trace directive is set in the options section (see _The Trace Directive_ on page 88).
The concept of items is further discussed in reference [Aho].

// PAGE 101

// @XREF: Level 2: String Synthesizing Technique
// @XREF: The Separator Part

For each state, a table containing all items in that state is written.
The table is labelled by the _state number_ and the _continuation symbol_ chosen by the second level error correction (see _Level 2: String Synthesizing Technique_ on page 74).
If _separators_ have been defined (see _The Separator Part_ on page 98), a _separator continuation symbol_ will be printed within parentheses if applicable for the state.

Each item in the state is represented by an entry in the table.
Each entry is labelled by the _parsing action_ for the item in the state.
The action has one of the following formats:

[horizontal]
`<number>` :::
The action for the item is _shift_ if the symbol following the dot is recognized.
The _number_ indicates the next state.
`{blank}'R'<number>` :::
The action for the item is _reduce_ by production _number_.
The production number refers to the number in the productions list.
`{blank}'SR'<number>` :::
The action for the item is _shift-reduce_ by production _number_.


The item itself follows the parsing action.
If the parsing action is _reduce_, the item is followed by the _follow set_ of terminals within curly braces.

Consider the following example:

// @TODO: Unless the '!' vertical divider is used in actual output generated
//        by ToolMaker, we should use a pipe '|' symbol instead.

.......................................................
State:  14  ! Continuation: '.' (';')
------------!------------------------------------------
        R39 ! <terms> --> <terms> <addop> <term> .
            !      { '.' ';' '=' '<' '>' '<>' '<=' '>='
            !        )' '+' '-' 'END' 'THEN' 'DO' }
         15 ! <term> --> <term> .<mulop> <factor>
       SR50 ! <mulop> --> .'*'
       SR51 ! <mulop> --> .'/'
.......................................................

The state number is 14, the continuation symbol is `.`, and the separator continuation symbol is `;`.
The parsing action for the first item is reduce by production 39, and the follow set which causes that reduction is enclosed in curly braces.
The parsing action for the second item is shift, and the next state is number 15 if a `<mulop>` is recognized.
The parsing action for the third item is shift-reduce by production 50 if a `{asterisk}` is the next token.

// @XREF: Grammar Ambiguity and LALR-conflicts

When the grammar is _ambiguous_, indicated by error message 303, the list file will contain information about the ambiguity.
If this is the case, the item sets for all offending states will be logged, and each state will be preceded by a line explaining the nature of the ambiguity (shift-reduce or reduce-reduce), followed by the offending symbol and the involved production or productions.
With this information it is normally possible to rewrite the grammar or use modification rules to resolve the ambiguity (see _Grammar Ambiguity and LALR-conflicts_ on page 68).

// PAGE 102

=== Format of the Parser Tables

The parser tables are printed as matrices.
Each _row_ is labelled with a _state number_, and the state is also identified by the symbol before the dot in the first item of the state.
The _columns of the action table_ are labelled with the internal codes of the _terminals_, and the _columns of the goto table_ are labelled with the internal codes of the _non-terminals_.
An entry in the table has one of the following formats:

[horizontal]
`{blank}'S'<number>` :: meaning _shift_ the symbol and goto state _number_.
`{blank}'R'<number>` :: meaning _reduce_ using production _number_.
`{blank}'-'<number>` :: meaning _shift_ the symbol and reduce using production _number_.
`{blank}'A'` :: meaning _accept_ the input.
`{blank}'X'` :: meaning _error_.
`{blank}'*'` :: meaning _don't care_, i.e. the entry can never be reached.

// @BIBLIO_ENTRY: [Sencker]

If table packing is activated, the packed parser tables and the various access structures will also be printed.
In order to understand the purpose of the various access structures it is necessary to understand the theory behind the various packing methods, see reference [Sencker].
The entries in the packed parser tables have the same format as described above.


== The Vocabulary File

The vocabulary file contains the representation and codes of the terminal symbols, and it constitutes the interface between the scanner and the parser.
If ScannerMaker is used, it uses this file to construct a scanner for the vocabulary of the language.

The vocabulary file contains one line for each terminal that the parser expects the scanner to recognize.
Each line has the following format:

// @CHECK: The "<vocabulary entry> :==" is like that in original.
//         Maybe a typo? => "<vocabulary entry> ::="

// SYNTAX: EBNF

------------------------------
<vocabulary entry> :==
    <sequence number>
    <scanner code>
    <terminal string>
    <vocabulary name>

<sequence number> ::= <decimal integer>

<scanner code> ::= <decimal integer>

<terminal string> ::= TERMINAL

<vocabulary name> ::= 'main'
------------------------------

// PAGE 103

The `<sequence number>` is a pure sequence number starting from 1.

// @XREF: The Token Section

The `<scanner code>` is the number the scanner is supposed to return to the parser in the code member of the token structure (see _The Token Section_ on page 36) when the corresponding token has been recognized.

The `<terminal string>` is the string representing the terminal to be recognized.
The appearance is exactly the same as in the grammar file.
This may be either a string or an identifier representing lexical items needing further definition (e.g. by regular expressions in a scanner generator).

IMPORTANT: Only normal identifiers can be used in the vocabulary file, i.e. as identifiers for tokens.
Angle bracketed strings are _not_ recognized by ScannerMaker.

// @XREF: Vocabulary
// @XREF: The Vocabulary file
// @XREF: ScannerMaker Reference Manual

Last on each line is an identifier indicating to which vocabulary this token belongs.
This is to comply with the ScannerMaker ability to handle multiple vocabularies (see _Vocabulary_ on page 134 and _The Vocabulary file_ in the _ScannerMaker Reference Manual_, page 160).

TIP: ParserMaker assumes that all tokens should belong to the main vocabulary, but by editing this file (e.g. automatically through a stream editor) tokens may be placed in different vocabularies.
